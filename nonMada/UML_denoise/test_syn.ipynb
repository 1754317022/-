{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from Autoencoder import Autoencoder\n",
    "\n",
    "def next_batch_random(train_data, batch_size):  \n",
    "    index = [ i for i in range(0,len(train_data)) ]  \n",
    "    np.random.shuffle(index);  \n",
    "    batch_data = []; \n",
    "    for i in range(0,batch_size):  \n",
    "        batch_data.append(train_data[index[i]]);         \n",
    "    return batch_data\n",
    "\n",
    "Dtrain=np.fromfile(\"Datapre/syn_A.dat\",dtype=np.float64)\n",
    "Dtrain=Dtrain.reshape(6000,1600)\n",
    "\n",
    "Dtest11=np.fromfile(\"Datapre/syn_A0.dat\",dtype=np.float64)\n",
    "Dtest11=Dtest11.reshape(60,1600)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_samples=len(Dtrain)\n",
    "training_epochs =10\n",
    "batch_size = 100\n",
    "display_step = 1\n",
    "\n",
    "corruption_level = 0.0\n",
    "sparse_reg=1\n",
    "#\n",
    "n_inputs = 1600\n",
    "n_hidden = 3200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "ae = Autoencoder(n_layers=[n_inputs, n_hidden],\n",
    "                          transfer_function = tf.nn.sigmoid,\n",
    "                          optimizer = tf.compat.v1.train.AdamOptimizer(learning_rate = 0.001),ae_para = [corruption_level, sparse_reg])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "init = tf.compat.v1.global_variables_initializer()\n",
    "sess = tf.compat.v1.Session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess.run(init)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NO of Epochs 10 N_samples 6000 NO total_batches 400 batch size 15\n",
      "Epoch: 1, Cost: nan\n",
      "NO of Epochs 10 N_samples 6000 NO total_batches 400 batch size 15\n",
      "Epoch: 2, Cost: nan\n",
      "NO of Epochs 10 N_samples 6000 NO total_batches 400 batch size 15\n",
      "Epoch: 3, Cost: nan\n",
      "NO of Epochs 10 N_samples 6000 NO total_batches 400 batch size 15\n",
      "Epoch: 4, Cost: nan\n",
      "NO of Epochs 10 N_samples 6000 NO total_batches 400 batch size 15\n",
      "Epoch: 5, Cost: nan\n",
      "NO of Epochs 10 N_samples 6000 NO total_batches 400 batch size 15\n",
      "Epoch: 6, Cost: nan\n",
      "NO of Epochs 10 N_samples 6000 NO total_batches 400 batch size 15\n",
      "Epoch: 7, Cost: nan\n",
      "NO of Epochs 10 N_samples 6000 NO total_batches 400 batch size 15\n",
      "Epoch: 8, Cost: nan\n",
      "NO of Epochs 10 N_samples 6000 NO total_batches 400 batch size 15\n",
      "Epoch: 9, Cost: nan\n",
      "NO of Epochs 10 N_samples 6000 NO total_batches 400 batch size 15\n",
      "Epoch: 10, Cost: nan\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(training_epochs):\n",
    "    avg_cost = 0\n",
    "    total_batch = int(n_samples / batch_size)\n",
    "    print(\"NO of Epochs\",training_epochs,\"N_samples\",n_samples,\"NO total_batches\",total_batch,\"batch size\",batch_size)\n",
    "    # Loop over all batches\n",
    "    for i in range(total_batch):\n",
    "#        batch_xs= Dtrain[i*batch_size:(i+1)*batch_size,:] #just consider x, not ylabel\n",
    "#        ass=mnist.train.images\n",
    "        batch_xs=next_batch_random(Dtrain,batch_size)\n",
    "        # Fit training using batch data\n",
    "        #temp = ae.partial_fit()\n",
    "        cost, opt = sess.run(ae.partial_fit(), feed_dict={ae.x: batch_xs, ae.keep_prob : ae.in_keep_prob})\n",
    "        print(cost)\n",
    "        print(opt)\n",
    "        # Compute average loss\n",
    "        avg_cost += cost / n_samples * batch_size\n",
    "\n",
    "    # Display logs per epoch step\n",
    "    if epoch % display_step == 0:\n",
    "        print(\"Epoch:\", '%d,' % (epoch + 1),\n",
    "              \"Cost:\", \"{:.9f}\".format(avg_cost))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total cost: nan\n"
     ]
    }
   ],
   "source": [
    "ae_test_cost = sess.run(ae.calc_total_cost(), feed_dict={ae.x: Dtest11, ae.keep_prob : ae.in_keep_prob})\n",
    "print(\"Total cost: \" + str(ae_test_cost))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test Process\n",
    "drecon11 = sess.run(ae.reconstruct(), feed_dict={ae.x: Dtest11, ae.keep_prob : ae.in_keep_prob})\n",
    "Drecon11=drecon11.astype(np.float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "Drecon11.tofile(\"Datapre/syn_A1.dat\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
